对数几率回归                                Nov 3，2018
Author：BuJiBuJi HuYi
Summary：
    
LastUpDate:Nov 3, 2018

==================================================================

== Content ==

1、已知线性回归的基本形式，是得到一条线，让各个样本点距离该直线的距离之和最短。
    - 基本形式：

{{file:../images/线性回归基本形式.png}}

2、人们想，我的样本是具有指数增长的特点的，那能不能回归出一条指数曲线，也让各样本点距离这个曲线的距离值和最短呢，于是就在基本形式上加上ln实现了对数线性回归。

{{file:../images/对数线性回归.png}}

3、更一般的广义线性模型，是扩充了上述思路，让更多的曲线函数使用线性回归的思想。


4、对数几率回归出场：
    - 首先是单位阶跃函数（高于某个值就标记为1，低于某个值就标记为-1），这样可以完成**分类任务**。


{{file:../images/单位阶跃函数.png}}


    - 单位阶跃函数不是连续的不能符合第三条的广义线性模型的要求，所以需要找个替代函数,模拟出类似单位阶跃函数的形式
    - *对数几率函数正是常用的替代函数，可以实现阶跃函数的替代，也符合广义线性模型*
    - 

{{file:../images/对数几率函数.png}}

5、使用注意：

类别不平衡的问题。之前的假设都是不同类别的训练样例数目相当，稍有差别问题不大，但如果差别很大，就会有问题

例如998个反例，3个正例。

见书 P66 P67页的说明。

== 作业 ==

----
用算法的语言描述对数几率回归算法的过程

**输入：** 训练集 D

**目标：** 给出训练集的分类（二分类）

**过程:**
- 预处理测试数据
    - 读取 csv 数据文件
    - 处理空值数据
    - 切分训练集和测试集
- 定义 likelihood_sub()求解如下公式的值
    -  -y * np.dot(beta, x.T) + np.math.log(1 + np.math.exp(np.dot(beta, x.T)))
    
    {{file:../images/sub_likelihood.png}}

- 定义 likelihood(), 对每个样本的 likelihood_sub() 值求和
    -  for i in range( 样本数）
    -       sum += likelihood_sub()
    -  return sum 
 
    {{file:../images/likelihood.png}}

- 定义  定义牛顿法求极值的函数, 返回最佳参数 w 和 b

- 计算样本分类 z>0 为分类1，z<=0  为分类0

- 与样本 label 比较得出混淆矩阵

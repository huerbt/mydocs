亲爱的⽤用户，您使⽤用了了⼴广告屏蔽软件，⼴广告是CSDN向您免费提供服务与产品的重要⽀支持，希望您将csdn.net加⼊入AdBlock Plus⽩白名单，感谢⽀支持！

博客 学院 下载 图⽂文课 论坛 APP 问答 商城 VIP会员 活动 招聘 ITeye GitChat 博客 学院 下载 图⽂文课 论坛 APP 问答 商城 VIP会员 活动 招聘 ITeye GitChat

搜博主⽂文章 搜博主⽂文章

写博客 写博客

发Chat 发Chat

传资 传资
4

原 周志华《机器器学习》课后习题解答系列列（四）：Ch3.3 - 编程实现对率回归

9

2017年年03⽉月19⽇日 13:53:42 Snoopy_Yuan 阅读数：6978 标签：
个⼈人分类： 机器器学习

机器器学习

对率回归

梯度下降法

python

sklearn 更更多

版权声明：本⽂文为博主原创⽂文章，转载时请注明来源。 h!ps://blog.csdn.net/Snoopy_Yuan/ar"cle/details/63684219
这⾥里里采⽤用Python-sklearn的⽅方式，环境搭建可参考 数据挖掘⼊入⻔门：Python开发环境搭建（eclipse-pydev模式）.
相关答案和源代码托管在我的Github上：PY131/Machine-Learning_ZhouZhihua.
思路路概要
编程实现对率回归： * 采⽤用sklearn逻辑斯蒂回归库函数实现，通过查看混淆矩阵，绘制决策区域来查看模型分类效果； * ⾃自⼰己编程实现，从极⼤大化似然函数出发，采⽤用梯度下降法得到最优参数，然后尝试了了随机梯度下降法来优化过程。
3.3 编程实现对率回归

所使⽤用的数据集如下：

本题是本书的第⼀一个编程练习，采⽤用了了⾃自⼰己编程实现和调⽤用sklearn库函数两种不不同的⽅方式，详细解答和编码过程：（查看完整代码）：

1.获取数据、查看数据、预处理理：

观察数据可知，X包含（密度、含糖量量）两个变量量，y为⻄西⽠瓜是否好⽠瓜分类（⼆二分），由此⽣生成.csv数据⽂文件，在Python中⽤用Numpy读取数据并采⽤用matplo 可视化数据：

样例例代码： 开发者调查 AI开发者⼤大会⽇日程曝光 Oﬃce 365商业协作版 5折钜惠！

登录

注册

1 '''

星⼒力力捕⻥鱼

⽹网店转让平台

2 data importion

3 '''

4 import numpy as np

5 import matplotlib.pyplot as plt

6

7 # load the CSV ﬁle as a numpy matrix

8 dataset = np.loadtxt('../data/watermelon_3a.csv', delimiter=",")

9

10 # separate the data from the target attributes

11 X = dataset[:,1:3]

12 y = dataset[:,3]

13

14 # draw scatter diagram to show the raw data

15 f1 = plt.ﬁgure(1)

16 plt.title('watermelon_3a')

17 plt.xlabel('density')

18 plt.ylabel('ratio_sugar')

19 plt.scatter(X[y == 0,0], X[y == 0,1], marker = 'o', color = 'k', s=100, label = 'bad')

20 plt.scatter(X[y == 1,0], X[y == 1,1], marker = 'o', color = 'g', s=100, label = 'good')

21 plt.legend(loc = 'upper right')

22 plt.show()

数据散点图：

2.采⽤用sklearn逻辑回归库函数直接拟合：
虽然样本量量很少，这⾥里里还是先划分训练集和测试集，采⽤用sklearn.model_selection.train_test_split()实现，然后采⽤用sklearn.linear_model.LogisticRegressio 于训练集直接拟合出逻辑回归模型，然后在测试集上评估模型（查看混淆矩阵和F1值）。
样例例代码：
1 ''' 2 using sklearn lib for logistic regression 3 ''' 4 from sklearn import model_selection 5 from sklearn.linear_model import LogisticRegression 6 from sklearn import metrics 7 8 9 # generalization of test and train set 10 X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.5, random_state=0) 11 12 # model training

13 log_model = LogisticRegression() 14 log_model.ﬁt(X_train, y_train) 15 16 # model testing 17 y_pred = log_model.predict(X_test) 18 19 # summarize the accuracy of ﬁtting 20 print(metrics.confusion_matrix(y_test, y_pred)) 21 print(metrics.classiﬁcation_report(y_test, y_pred))

得出混淆矩阵和相关度量量（查准率（准确率）、查全率（召回率），F1值）结果如下：

1 [[4 1]

2 [1 3]]

3

precision

4

5

0.0

0.80

6

1.0

0.75

7

8 avg / total

0.78

recall f1-score support

0.80

0.80

5

0.75

0.75

4

0.78

0.78

9

由混淆矩阵可以看到，由于样本本身数量量较少，模型拟合效果⼀一般，总体预测精度约为0.78。为提升精度，可以采⽤用⾃自助法进⾏行行重抽样扩充数据集，或是 叉验证选择最优模型。
下图是采⽤用matplotlib.contourf绘制的决策区域和边界，可以看出对率回归分类器器还是成功的分出了了绝⼤大多数类：

3.⾃自⼰己编程实现逻辑斯蒂回归
编程实现逻辑回归的主要⼯工作是求取参数w和b（⻅见书p59），最常⽤用的参数估计⽅方法是极⼤大似然法，由于题3.1已经证得对数似然函数（⻅见书3.27）是凸函 在最优解，这⾥里里考虑采⽤用梯度下降法来迭代寻优。 回顾⼀一下Sigmoid函数，即逻辑斯蒂回归分类器器的基础模型：
⽬目的是基于数据集求出最优参数w和b，最常采⽤用的是极⼤大似然法，参数的似然函数为：

根据书p59，最⼤大化上式等价于最⼩小化下式：
题3.2已证上式为凸函数，⼀一定存在最⼩小值，但按照导数为零的解析求解⽅方式较为困难，于是考虑采⽤用梯度下降法来求解上式最⼩小值时对应的参数。 注：梯度下降法基本知识可参考书中附录p409⻚页，也可直接采⽤用书中p60式3.30偏导数公式。书中关于参数迭代改变式⼦子如下：

对于迭代，可每次先根据(B.16)计算出梯度▽f(β)，然后由(B.17)更更新得出下⼀一步的Δβ。 接下来编程实现基本的梯度下降法： (1)⾸首先编程实现对象式3.27：

1 def likelihood_sub(x, y, beta):

2

'''

3

@param x: one sample variables

4

@param y: one sample label

5

@param beta: the parameter vector in 3.27

6

@return: the sub_log-likelihood of 3.27

7

'''

8

return -y * np.dot(beta, x.T) + np.math.log(1 + np.math.exp(np.dot(beta, x.T)))

9

10 def likelihood(X, y, beta):

11

'''

12

@param X: the sample variables matrix

13

@param y: the sample label matrix

14

@param beta: the parameter vector in 3.27

15

@return: the log-likelihood of 3.27

16

'''

17

sum = 0

18

m,n = np.shape(X)

19

20

for i in range(m):

21

sum += likelihood_sub(X[i], y[i], beta)

22

23

return sum

(2)然后基于训练集（注意x->[x,1]），给出基于3.27似然函数的定步⻓长梯度下降法，注意这⾥里里的偏梯度实现技巧：

1 '''

2 @param X: X is the variable matrix

3 @param y: y is the label array

4 @return: the best parameter estimate of 3.27

5 '''

6 def gradDscent_1(X, y): #implementation of basic gradDscent algorithms

7

8

h = 0.1 # step length of iteration

9

max_times= 500 # give the iterative times limit

10

m, n = np.shape(X)

11

12

beta = np.zeros(n) # parameter and initial to 0

13

delta_beta = np.ones(n)*h # delta parameter and initial to h

14

llh = 0

15

llh_temp = 0

16

17

for i in range(max_times):

18

beta_temp = beta.copy()

19

20

# for partial derivative

21

for j in range(n):

22

beta[j] += delta_beta[j]

23

llh_tmp = likelihood(X, y, beta)

24

delta_beta[j] = -h * (llh_tmp - llh) / delta_beta[j]

25

beta[j] = beta_temp[j]

26

27

beta += delta_beta

28

llh = likelihood(X, y, beta)

29

30

return beta

通过追踪参数，查看其收敛曲线，然后来调节相关参数（步⻓长h，迭代次数max_times）。下图是在当前参数取值下的beta曲线，可以看到其收敛良好：

(3)最后建⽴立Sigmoid预测函数，对测试集数据进预测，得到混淆矩阵如下：
1 [[ 4. 1.] 2 [ 1. 3.]]

可以看出其总体预测精度（7/9 ≈ 0.78）与调⽤用sklearn库得出的结果相当。 (4)采⽤用随机梯度下降法来优化：上⾯面采⽤用的是全局定步⻓长梯度下降法（称之为批量量梯度下降），这种⽅方法在可能会⾯面临收敛过慢和收敛曲线波动情况的同 次迭代需要全局计算，计算量量随数据量量增⼤大⽽而急剧增⼤大。所以尝试采⽤用随机梯度下降来改善参数迭代寻优过程。 随机梯度下降法的核⼼心思想是增量量学习：⼀一次只⽤用⼀一个新样本来更更新回归系数，从⽽而形成在线流式处理理。 同时为了了加快收敛，采⽤用变步⻓长的策略略，h随着迭代次数逐渐减⼩小。 给出变步⻓长随机梯度下降法的代码如下：

1 def gradDscent_2(X, y): #implementation of stochastic gradDscent algorithms

2 '''

3

@param X: X is the variable matrix

4

@param y: y is the label array

5

@return: the best parameter estimate of 3.27

6

'''

7

import matplotlib.pyplot as plt

8

9

m, n = np.shape(X)

10

h = 0.5 # step length of iterator and initial

11

beta = np.zeros(n) # parameter and initial

12

delta_beta = np.ones(n) * h

13

llh = 0

14

llh_temp = 0

15

16

for i in range(m):

17

beta_temp = beta.copy() # for partial derivative

18

19

for j in range(n):

20

h = 0.5 * 1 / (1 + i + j) # change step length of iterator

21

beta[j] += delta_beta[j]

22

llh_tmp = likelihood_sub(X[i], y[i], beta)

23

delta_beta[j] = -h * (llh_tmp - llh) / delta_beta[j]

24

beta[j] = beta_temp[j]

25

26

beta += delta_beta

27

llh = likelihood_sub(X[i], y[i], beta)

28

29

return beta

30

得出混淆矩阵：

1 [[ 3. 2.] 2 [ 0. 4.]]

从结果看到的是：由于这⾥里里的⻄西⽠瓜数据集并不不⼤大，所以随机梯度下降法采⽤用⼀一次遍历所得的结果不不太好，参数也没有完成收敛。这⾥里里只是给出随机梯度下 实现样例例，这种⽅方法在⼤大数据集下相⽐比批量量梯度法应会有明显的优势。

参考链接： 由于这是本书第⼀一个编程，索引资料料较多，择其重要的⼀一些列列出如下：
Introduction to Machine Learning with Python and Scikit-Learn scikit-learn官⽅方主⻚页 matplotlib官⽅方主⻚页 随机梯度下降（Stochastic gradient descent）和批量量梯度下降（Batch gradient descent）的公式对⽐比、实现对⽐比 机器器学习算法与Python实践之（七）逻辑回归（Logistic Regression） plot decision boundary matplotlib Ask（matplotlib决策区域和边界绘制 Python数据可视化——散点图

⼏乎没⼈知道！微信新出的这个赚钱功能简直赚疯了！
富洋松旺 · 燨燚
Python爬⾍虫全栈教学，零基础教你成编程⼤大神
零基础学爬⾍虫，你要掌握学习那些技能？
想对作者说点什什么？ 我来说⼀一句句
qq_40530372： 利利⽤用随机梯度下降法求出的混淆矩阵跟您给出的不不⼀一样，⽤用你的GitHub上的源码 (21⼩小时前 #6楼) xiaocuishuoshu： plt.sca!er(X[y == 0,0], X[y == 0,1], marker = 'o', color = 'k', s=100, label = 'bad') plt.sca!er(X[y == 1,0], X[y == 1,1], marker = 'o', color = 'g', s=100, label = 'goo 主，命令中[y == 0,0], X[y == 0,1]是什什么意思？在怎么有两个取值？ (3周前 #5楼)

m0_37709336： 您好，有个⼩小疑问：GradDecent函数（批量量梯度下降函数）第18⾏行行:beta_tmp = beta和第25⾏行行:beta[j] = beta_tmp[j]。我理理解的意义为：只变化⼀一个维度x⼤大 其他维度x不不变求得在这个维度的delta_beta。但是有⼀一点很疑惑，beta_tmp ＝ beta,使得这两个变量量指向同⼀一个底层矩阵对象，即使得：beta[j] = beta_tmp[j]失效了了（我的 beta_tmp ＝ beta,使得beta_tmp赋值为⼀一个指针，其值等于beta，即指向同⼀一个对象。使得，beta[j] = beta_tmp[j]失效，因为beta_tmp[j]被21⾏行行的beta[j] += delta_beta[j]改变 第18⾏行行改成：beta_tmp = np.array(beta)可能才是您的原本意义，但是这样求得的beta和您给出的beta收敛曲线中得到的值不不⼀一样。对这点很疑惑。 (6个⽉月前 #4楼)
查看回复(1)
项慈航： 公式中是beta转秩乘x，你实现为何是相反的？暂时数学⽐比较渣，困惑多时，麻烦指点下 (1年年前 #3楼) 查看回复(1)
⻜飞⾬雨新⻛风： 图上⾯面我没找到（0.243,0.267）这个点 (1年年前 #2楼)
⻜飞⾬雨新⻛风： 数据点有(0.243，0.267)但是到了了你这⾥里里有没有了了，你⽤用错数据了了~~~ (1年年前 #1楼) 查看回复(1)

机器器学习(周志华) 参考答案 第三章 线性模型 3.3
机器器学习(周志华) 参考答案 第三章 线性模型 3.3机器器学习(周志华⻄西⽠瓜书) 参考答案 …

1.1万 来⾃自： 我的博客

⻄西⽠瓜书 习题3.3 编程实现对数⼏几率回归，梯度下降法
最近⼊入坑上道了了，跟着周志华⽼老老师的《机器器学习》，先搞个课后题练练⼿手。 我电脑…

1301 来⾃自： 世靖的码场

周志华机器器学习，3.3编程实现对率回归，并给出⻄西⽠瓜数据集3.0α上的结果

4278

3.3编程实现对率回归，并给出⻄西⽠瓜数据集3.0α上的结果数据集： 1 0.697 0.460 1 2 … 来⾃自： zjy_lilas的博客

30W年年薪的⼈人⼯工智能⼯工程师只是“⽩白菜价”？
机器器学习|深度学习|图像处理理|⾃自然语⾔言处理理|⽆无⼈人驾驶，这些技术都会吗？看看真正的⼈人⼯工智能师都会那些关键…
区块链开发⼋八周学会，⼩小⽩白程序员都能学？
区块链DApp开发学习⼤大纲免费领

Linux Socket编程实战第1季第1部分

学院

适合⼈人群：1、有C语⾔言基础 ；2、对⽹网络通讯感兴趣的⼈人员；3、从事⽹网络通讯的技术⼈人员； 4、在校学⽣生；,…

⽤用对数⼏几率回归实现周志华《机器器学习》习题3.3⻄西⽠瓜分类，python编程

2716

数据集如下，要求根据⻄西⽠瓜的两个属性x1(密度)，x2(含糖率)实现对⻄西⽠瓜好⽠瓜（1）… 来⾃自： ⼤大树挖掘⼯工的博客

《机器器学习》周志华 课后习题3.3：编程实现对率回归,并给出⻄西⽠瓜数据集 …

1309

数据如下： python 代码如下： #!/usr/bin/env python3 # -*- coding: u$-8 -*- """ Cre…

来⾃自： llwleon的博客

《机器器学习（周志华）》习题3.3答案
编程实现对率回归，并给出⻄西⽠瓜数据集3.0@上的结果。 对率回归即逻辑回归，可以…

2891 来⾃自： 勿忘初衷

机器器学习（周志华）习题3.3

336

本⼈人菜⻦鸟⼀一枚，由于需要完成作业，所以尝试使⽤用机器器学习⼯工具库去解决该题（周… 来⾃自： CHNguoshiwush…

⼏乎没⼈知道！微信新出的这个赚钱功能简直赚疯了！
富洋松旺 · 燨燚
劲爆！⽯家庄25岁美⼥⽤微信做这个，1个⽉存款吓呆⽗母！
煜隆投资 · 燨燚

你⾛走过最⻓长的路路,就是机器器学习过程中的弯路路 - AI科技⼤大..._CSDN博客
营⻓长的⼀一位转型AI的朋友,最近对营⻓长抱怨,“⾛走过的最远的路路,就是机器器学习过程中的弯路路”,然后开始各种blabl...

机器器学习系列列(⼀一)——机器器学习简介 - CSDN博客
前前后后接触机器器学习也有⼀一年年时间,但⼀一直没有系统整理理总结过。从本篇博客开始,将记录下我的学习内容与参考资料料,系列列按照李李宏毅的机器器学习课程,吴恩达的机器器学习课程...

你⾛走过最⻓长的路路,就是机器器学习过程中的弯路路 - AI科技⼤大..._CSDN博客
营⻓长的⼀一位转型AI的朋友,最近对营⻓长抱怨,“⾛走过的最远的路路,就是机器器学习过程中的弯路路”,然后开始各种blabl...

机器器学习系列列(⼀一)——机器器学习简介 - CSDN博客
前前后后接触机器器学习也有⼀一年年时间,但⼀一直没有系统整理理总结过。从本篇博客开始,将记录下我的学习内容与…

机器器学习(周志华) 参考答案 第三章 线性模型
机器器学习(周志华) 参考答案 第三章 线性模型 机器器学习(周志华⻄西⽠瓜书) 参考答案 总⽬目…

2万 来⾃自： 我的博客

相关热词 周志华 周志华课题组 周志华 勘误 周志华 线性模型 周志华研究⽣生

3.3编程实现对率回归
&quot;&quot;&quot; Author: Victoria Created on: 2017.9.14 11:00 &quot;&quot;&q…

338 来⾃自： 周博的博客

Snoopy_Yuan 关注 40篇⽂文章

carson0408 关注 166篇⽂文章

steve_99 关注 75篇⽂文章

《机器器学习有意思! 01》- 世界上最简单的机器器学习⼊入⻔门
本⽂文⾸首发于h!ps://jizhi.im/blog/post/ml_is_fun_01 你是否也曾听⼈人们谈起机器器学习但是只有⼀一个朦胧的概念?你是否厌倦了了在同事的⾼高谈阔论中颓然欲睡?此诚求...

图解⼗十⼤大经典机器器学习算法⼊入⻔门 - jrunw的博客 - CSDN博客
传统的机器器学习算法包括决策树、聚类、⻉贝叶斯分类、⽀支持向量量机、EM、Adaboost等等。这篇⽂文章将对常⽤用算法做常识性的介绍,没有代码,也没有复杂的理理论推导,就是图解...

《机器器学习有意思! 01》- 世界上最简单的机器器学习⼊入⻔门
本⽂文⾸首发于h!ps://jizhi.im/blog/post/ml_is_fun_01 你是否也曾听⼈人们谈起机器器学习但是只有⼀一个朦胧的概念?你…

图解⼗十⼤大经典机器器学习算法⼊入⻔门 - jrunw的博客 - CSDN博客
传统的机器器学习算法包括决策树、聚类、⻉贝叶斯分类、⽀支持向量量机、EM、Adaboost等等。这篇⽂文章将对常⽤用…

对率回归的实验

141

对数⼏几率回归在python中的实现 在做分类任务时，需要找⼀一个单调可微函数将分类… 来⾃自： qq_28915885的…

机器器学习(周志华)-python编程练习-习题3-3
习题3.3 编程实现对率回归，并给出⻄西⽠瓜数据集 3.0α 上的结果. 数据集3.0α sn den…

19 来⾃自： bebusy的专栏

机器器学习-周志华-课后习题答案-线性模型

1325

3.1试分析在什什么情况下，在以下式⼦子中不不⽐比考虑偏置项b。答：在线性回归中，所… 来⾃自： 天台的猫爷爷的…

⽯家庄90后⼩伙在家⽆聊玩微信，存款惊呆⽗母
东平商贸 · 燨燚
劲爆，靠死⼯资怎么买房买车，聪明⼈是这样赚钱！
投资 · 燨燚

matlab⾃自定义函数的⼏几种⽅方法
1、函数⽂文件+调⽤用命令⽂文件：需单独定义⼀一个⾃自定义函数的M⽂文件; 2、函数⽂文件+…

2.6万 来⾃自： yuxiaoxi21的博客

Matlab中如何定义函数
1.在m⽂文件中，func"on y=f(x) %函数的声明 y=x^2就是建⽴立了了⼀一个y=x2y=x^2的函…

1.3万 来⾃自： Katherine_S的专…

调⽤用⾃自⼰己编写的matlab函数
在matlab中调⽤用⾃自定义的函数

4.2万 来⾃自： without_scruple…

对数⼏几率回归（Logis#c Regression）总结
逻辑回归logis"c regression，虽然名字是回归，但是实际上它是处理理分类问题的算…

4966 来⾃自： code_caq的博客

周志华《机器器学习》习题3.3
编程实现对数回归，并给出⻄西⽠瓜数据集3.0α\alpha上的结果。 既然是编程实现，就…

748 来⾃自： WUTab的博客

哈佛⼤大学录取分
百度⼴告

8
3分钟了了解⼊入⻔门「机器器学习」该学习什什么?(上) - GitChat..._CSDN博客

本⽂文来⾃自作者 粽⼦子 在 GitChat 上分享「零基础的新⼿手,如何⼊入⻔门机器器学习?」,「阅读原⽂文」查看交流实录 「⽂文末⾼高能」 编辑 | 坂本 ⼀一、机器器学习⼊入⻔门浅谈...

⼀一张图看懂AI、机器器学习和深度学习的区别 - dukai392的..._CSDN博客
要搞清它们的关系,最直观的表述⽅方式就是同⼼心圆,最先出现的是理理念,然后是机器器学习,当机器器学习繁荣之后就出现了了深度学习,今天的AI⼤大爆发是由深度学习驱动的。 从衰败...

3分钟了了解⼊入⻔门「机器器学习」该学习什什么?(上) - GitChat..._CSDN博客
本⽂文来⾃自作者 粽⼦子 在 GitChat 上分享「零基础的新⼿手,如何⼊入⻔门机器器学习?」,「阅读原⽂文」查看交流实录 「⽂文…

⼀一张图看懂AI、机器器学习和深度学习的区别 - dukai392的..._CSDN博客
要搞清它们的关系,最直观的表述⽅方式就是同⼼心圆,最先出现的是理理念,然后是机器器学习,当机器器学习繁荣之后就出…

机器器学习实战(⽤用Scikit-learn和TensorFlow进⾏行行机器器学习)(五)
上⼏几节讲述了了真实数据集在回归问题以及分类问题上的总流程，但是对于模型的选…

1822 来⾃自： %l_CSDN的博客

逻辑回归（Logis#c regression）详解-并⽤用scikit-learn训练逻辑回归拟合Ir…

4.9万

引⾔言这篇⽂文章主要介绍逻辑回归背后的⼀一些概率概念，给你⼀一些直观感觉关于它的…

来⾃自： Xurtle

Logis#c Regression（逻辑回归）
Logis"c回归思想，Python实现，应⽤用。Logis"c 回归是与线性回归相对应的⼀一种分…

806 来⾃自： 静敬澹⼀一

机器器学习之线性回归及代码示例例
⼀一、线性回归线性回归⼀一般⽤用来做连续值的预测，预测的结果为⼀一个连续值。因训…

7252 来⾃自： cxmscb的博客

周志华《机器器学习》课后习题解答系列列（五）：Ch4 - 决策树

4605

本章讲述决策树的相关内容，包括决策树的⽣生成，剪枝，连续值、缺失值的处理理，… 来⾃自： Snoopy_Yuan技…

⼗⼀⽉靠死⼯资怎么买房买车，聪明⼈是这样赚钱！
投资 · 燨燚
去银⾏转账，发现⽼婆的余额，瞬间吓坏了！！！
中乐咨询 · 燨燚

机器器学习（周志华）第四章习题解答

1650

转⾃自：h!p://blog.csdn.NET/wzmsltw/ar"cle/details/51059394 本⽂文是对周志华的《… 来⾃自： carson0408的博…

《机器器学习》周志华习题4.3答案
《机器器学习》周志华著，第四章课后习题4.3答案

3615 来⾃自： Just Do IT

机器器学习(周志华) 参考答案 第五章 神经⽹网络
机器器学习(周志华) 参考答案 第五章 神经⽹网络机器器学习(周志华⻄西⽠瓜书) 参考答案 总⽬目…

1.1万 来⾃自： 我的博客

机器器学习(周志华) 参考答案 第六章 ⽀支持向量量机 6.9
机器器学习(周志华) 参考答案 第六章 ⽀支持向量量机 6.9机器器学习(周志华⻄西⽠瓜书) 参考答…

2750 来⾃自： 我的博客

下载 编程实现对率回归，并给出⻄西⽠瓜数据集3.0a上的结果。
机器器学习的第⼀一次作业。周志华⽼老老师教材的p3.3。python实现対率回归，已给数据集

免费永久云主机
百度⼴告

10-14

机器器学习的⽅方法 - 修炼之路路 - CSDN博客
机器器学习(machine learning)是⼀一⻔门多领域交叉学科,涉及了了概率论、统计学、算法复杂度等多⻔门学科。专⻔门研究计算机怎样模拟或实现⼈人的学习⾏行行为,它能够发现和挖掘数据所...
3分钟了了解⼊入⻔门「机器器学习」该学习什什么?(下) - GitChat..._CSDN博客
本⽂文来⾃自作者 刘明 在 GitChat 上分享「机器器学习/深度学习书单推荐及学习⽅方法」,「阅读原⽂文」查看交流实录 「⽂文末⾼高能」 编辑 | 坂本 写在前⾯面 本⼈人是...

机器器学习的⽅方法 - 修炼之路路 - CSDN博客
机器器学习(machine learning)是⼀一⻔门多领域交叉学科,涉及了了概率论、统计学、算法复杂度等多⻔门学科。专⻔门研究…

3分钟了了解⼊入⻔门「机器器学习」该学习什什么?(下) - GitChat..._CSDN博客
本⽂文来⾃自作者 刘明 在 GitChat 上分享「机器器学习/深度学习书单推荐及学习⽅方法」,「阅读原⽂文」查看交流实录 …

机器器学习作业1 - 对率回归（逻辑回归）
使⽤用10折交叉验证法和留留⼀一法评测对率回归分类器器标题有点⻓长哈……这是第⼀一次作…

1919 来⾃自： Dapan同学

逻辑回归/对数⼏几率回归--⻄西⽠瓜书、统计学习总结

251

⼴广义模型可以解决分类任务。只需找到⼀一个单调可微函数将分类任务的真实标记y与… 来⾃自： zhangdamengcs…

对数⼏几率回归Logis#c Regression（Matlab）
这⾥里里的数据均来源于吴恩达⽼老老师机器器学习的课程。 上⼀一篇内容是线性回归，利利…

6769 来⾃自： XLM11的专栏

机器器学习—⻄西⽠瓜书-chapter3—对率回归
编程实现对率回归，并给出⻄西⽠瓜数据集3.0α上的结果 对率函数是任意阶可导的凸函…

215 来⾃自： 糖糖糖⾖豆的博客

《机器器学习》(周志华)课后习题参考答案
⽬目录： 周志华《机器器学习》课后习题解答系列列（⼆二）：Ch1 - 绪论周志华《机器器学…

3325 来⾃自： kchai31的博客

⼏乎没⼈知道！微信新出的这个赚钱功能简直赚疯了！
爱尚庄园 · 燨燚

⼏乎没⼈知道！⼿机新出的这个赚钱功能简直赚疯了！
上海永安 · 燨燚

matlab如何在⽂文中定义函数
matlab如何在⽂文中定义函数 通常我们多是将函数单独在编写在单个的m⽂文件中，再…

9514 来⾃自： lusongno1的博客

第三章 线性模型--机器器学习（周志华）参考答案

834

原⽂文的链接 机器器学习(周志华) 参考答案 第三章 线性模型 机器器学习(周志华⻄西⽠瓜书) 参… 来⾃自： qq_35218763的…

周志华 《机器器学习》之 第三章（线性模型）概念总结

2699

阅读之后，根据周志华⽼老老师对本章节的安排，⾸首先从线性模型的基本形式⼊入⼿手，逐… 来⾃自： 不不系之⾈舟的专栏…

使⽤用sklearn做各种回归
使⽤用sklearn做各种回归 基本回归：线性、决策树、SVM、KNN 集成⽅方法：随机森…

9274 来⾃自： Yeoman92的博客

⻄西⽠瓜书《机器器学习》课后答案——Chapter3_3.4
选择两个UCI数据集，⽐比较10折交叉验证法和留留⼀一法所估计出的对率回归的错误率…

1617 来⾃自： CodeTutor

⼗⼀⽉靠死⼯资怎么买房买车，聪明⼈是这样赚钱！
投资 · 燨燚

2018年微赚钱策略⼤公开，第⼀批⽹民已经赚翻了！
嘉超电⼦ · 燨燚

机器器学习⼊入⻔门好⽂文,强烈烈推荐 - Ri$er Liu的专栏 - CSDN博客
转⾃自 ⻜飞⻦鸟各投林林 史上最强---机器器学习经典总结---⼊入⻔门必读---⼼心⾎血总结---回味⽆无穷 让我们从机器器学习...
机器器学习基本概念梳理理 - ForLearning - CSDN博客
1. 什什么是机器器学习?权威定义: Arthur samuel: 在不不直接针对问题进⾏行行编程的情况下,赋予计算机学习能⼒力力的⼀一个研究领域。 Tom Mitchell: 对于某类任务T和性能度量量P,...
机器器学习⼊入⻔门好⽂文,强烈烈推荐 - Ri$er Liu的专栏 - CSDN博客
转⾃自 ⻜飞⻦鸟各投林林 史上最强---机器器学习经典总结---⼊入⻔门必读---⼼心⾎血总结---回味⽆无穷 让我们从机器器学习...

机器器学习基本概念梳理理 - ForLearning - CSDN博客
1. 什什么是机器器学习?权威定义: Arthur samuel: 在不不直接针对问题进⾏行行编程的情况下,赋予计算机学习能⼒力力的⼀一个…

周志华《机器器学习》课后习题解答系列列（五）：Ch4.3 - 编程实现ID3算法

2808

这⾥里里采⽤用了了⾃自⼰己编程的⽅方式实现ID3算法，并基于⻄西⽠瓜数据集⽣生成了了决策树，评估了了… 来⾃自： Snoopy_Yuan技…

⻄西⽠瓜书《机器器学习》课后答案——Chapter3_3.5
编程实现线性判别分析，并给出⻄西⽠瓜数据集3.0alpha上的结果。""" Author: Victoria …

1440 来⾃自： CodeTutor

机器器学习(周志华) 参考答案 第九章 聚类 9.10
机器器学习(周志华) 参考答案 第九章 聚类 9.10机器器学习(周志华⻄西⽠瓜书) 参考答案 总⽬目…

2013 来⾃自： 我的博客

《机器器学习》 --周志华版（⻄西⽠瓜书）--课后参考答案

2883

开始学习周志华版的《机器器学习》，将别⼈人写的课后习题的参考答案保存下来供参… 来⾃自： 这⾥里里记录着我⼀一…

logis#c回归概率详解

91

logis"c回归概率详解 上⼀一篇我们介绍了了线性代数的基本知识，并以PCA作为案例例进… 来⾃自： qq_40213457的…

免费永久云主机
百度⼴告
⽹网店店铺转让
百度⼴告

你应该知道的7种回归⽅方法

1.7万

本⽂文是我从国外⽹网站翻译⽽而来的⽂文章，如有错误之处，敬请指出！ 原⽂文标题：7 Ty… 来⾃自： Steve lock的blog…

机器器学习(周志华⻄西⽠瓜书) 参考答案 总⽬目录
机器器学习(周志华⻄西⽠瓜书)参考答案总⽬目录 从刚开始学习机器器学习到现在也有⼏几个⽉月…

8.2万 来⾃自： 我的博客

周志华《机器器学习》读书笔记（⼀一）
本书前⼏几章讲的都是基本术语，最硬核的数学部分很少，所以⽐比较简单。 机器器学习…

2167 来⾃自： garrulousabyss…

周志华机器器学习笔记（⼀一）
新⼈人⼀一枚，既是机器器学习的初学者，也是⾸首次发博客。谨以此记录我的学习体会，…

676 来⾃自： baidu_3840152…

机器器学习(周志华)习题解答1.1-1.3: 理理解假设和版本空间
本⽂文介绍版本空间，假设空间的概念并举例例求解。另外介绍和简单证明“没有免费的…

1.2万 来⾃自： ⾛走过的都是未来

免费永久云主机
百度⼴告
机器器学习(周志华) 参考答案 第⼀一章 绪论
机器器学习(周志华) 参考答案 第⼀一章 假设空间指的是问题所有假设组成的空间，我们…
逻辑回归模型推导及梯度下降
这⾥里里的逻辑回归模型，除了了重要要放在回归上，还要看到逻辑，所谓的逻辑其实就…

4万 来⾃自： 我的博客
488 来⾃自： 哆啦咪~fo

Snoopy_Yuan

关注

原创 40

粉丝 415

喜欢 70

评论 130

等级：

访问： 12万+

积分： 1334 勋章：

排名： 4万+

如何自学编程

更更多信息 Email: pn_yuan@163.com GitHub: h!ps://github.com/PnYuan

最新⽂文章
明星经纪人网站
Kaggle滑⽔水 - CTR预估（FM_FFM） Kaggle滑⽔水 - CTR预估（GBDT-LR） Kaggle滑⽔水 - CTR预估（LR） Kaggle滑⽔水 - 泰坦尼克之灾（决策树） 深度学习基础 - 对象检测（CNN+滑窗 +YOLO）

归档

2018年年6⽉月

3篇

2018年年4⽉月

2篇

2018年年3⽉月

3篇

2017年年10⽉月

2篇

2017年年7⽉月

6篇

2017年年6⽉月

展开

1篇

2017年年5⽉月

6篇

20个17⼈年人年分4类⽉月

8篇

2机0器1器7学年年习3⽉月

9篇 33篇

深度学习

8篇

概率图

1篇

数据挖掘

9篇

Hadoop

1篇

天池赛

展开

4篇

Kaggle

4篇

最新评论

周志华《机器器学习》课后习题解答系列列...
qq_40530372：利利⽤用随机梯度下降法求出的混淆 矩阵跟您给出的不不⼀一样，⽤用你的GitHub上的源码
周志华《机器器学习》课后习题解答系列列...
u012016803：CART_watermelon.py源码报错 <class> Traceback (m...
周志华《机器器学习》课后习题解答系列列...
huazeci：真是有⼼心⼈人
周志华《机器器学习》课后习题解答系列列...
catherined：[reply]liucheng_34[/reply] 感谢提示！

周志华《机器器学习》课后习题解答系列列...
mmm_jsw：作者出现了了⼀一处笔误，应该是：n1 = (2+1)(3+1)(3+1)+1 = 49种
开发⼀一个app多少钱

⾬⽔收集系统

⼀点点加盟

创意产品设计
联系我们

⼯业键盘

扫码联系客服

官⽅方公众号

QQ客服

kefu@csdn.net

客服论坛

400-660-0108

⼯工作时间 8:00-22:00

关于我们 招聘 ⼴广告服务 ⽹网站地图 百度提供站内搜索 京ICP证09002463号
©2018 CSDN版权所有

⽹网络110报警服务 经营性⽹网站备案信息 北北京互联⽹网违法和不不良信息举报中⼼心 中国互联⽹网举报中⼼心

联系我们

QQ客服

kefu@csdn.net

客服论坛

400-660-0108

⼯工作时间 8:00-22:00

关于我们 招聘 ⼴广告服务 ⽹网站地图 百度提供站内搜索 京ICP证09002463号
©2018 CSDN版权所有

⽹网络110报警服务 经营性⽹网站备案信息 北北京互联⽹网违法和不不良信息举报中⼼心 中国互联⽹网举报中⼼心

